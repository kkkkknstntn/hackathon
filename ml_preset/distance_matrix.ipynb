{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba055b1-a168-4385-83e9-3d636fcd0964",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T05:35:01.693816Z",
     "iopub.status.busy": "2025-05-17T05:35:01.692179Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:105: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2025-05-17 05:35:51.243613: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-17 05:35:59.048041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк: 375\n",
      "\n",
      "=== all-MiniLM-L6-v2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:05<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embeddings сохранены: (375, 384)\n",
      "… считаю матрицу расстояний (это O(N²) ≈ 0.1 М)\n",
      "✓ Distance-matrix сохранена: distances/all-MiniLM-L6-v2/cosine_distances.csv\n",
      "… рисую heatmap\n",
      "✓ Heatmap сохранён: heatmaps/all-MiniLM-L6-v2.png\n",
      "\n",
      "=== all-mpnet-base-v2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:04<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embeddings сохранены: (375, 768)\n",
      "… считаю матрицу расстояний (это O(N²) ≈ 0.1 М)\n",
      "✓ Distance-matrix сохранена: distances/all-mpnet-base-v2/cosine_distances.csv\n",
      "… рисую heatmap\n",
      "✓ Heatmap сохранён: heatmaps/all-mpnet-base-v2.png\n",
      "\n",
      "=== bge-base-en-v1.5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:04<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embeddings сохранены: (375, 768)\n",
      "… считаю матрицу расстояний (это O(N²) ≈ 0.1 М)\n",
      "✓ Distance-matrix сохранена: distances/bge-base-en-v1.5/cosine_distances.csv\n",
      "… рисую heatmap\n",
      "✓ Heatmap сохранён: heatmaps/bge-base-en-v1.5.png\n",
      "\n",
      "=== bge-large-en-v1.5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:11<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embeddings сохранены: (375, 1024)\n",
      "… считаю матрицу расстояний (это O(N²) ≈ 0.1 М)\n",
      "✓ Distance-matrix сохранена: distances/bge-large-en-v1.5/cosine_distances.csv\n",
      "… рисую heatmap\n",
      "✓ Heatmap сохранён: heatmaps/bge-large-en-v1.5.png\n",
      "\n",
      "=== roberta-large ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name roberta-large. Creating a new one with mean pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Batches: 100%|██████████| 12/12 [00:11<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Embeddings сохранены: (375, 1024)\n",
      "… считаю матрицу расстояний (это O(N²) ≈ 0.1 М)\n",
      "✓ Distance-matrix сохранена: distances/roberta-large/cosine_distances.csv\n",
      "… рисую heatmap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name microsoft/deberta-v3-large. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Heatmap сохранён: heatmaps/roberta-large.png\n",
      "\n",
      "=== deberta-v3-large ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Batches: 100%|██████████| 12/12 [00:18<00:00,  1.52s/it]"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\"\"\"\n",
    "Jupyter notebook cell 0\n",
    "Подготовка окружения\n",
    "\"\"\"\n",
    "import os, json, math, random, pathlib, itertools, textwrap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns         # только для красивой тепловой карты\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "cell 1\n",
    "Читаем данные\n",
    "\"\"\"\n",
    "DATA_PATH = \"../logs_with_labels.csv\"     # путь к csv\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df[\"id\"] = df.index                       # явный id, чтобы не потерять строки\n",
    "texts = df[\"errors\"].astype(str).tolist() # список строковых сообщений\n",
    "N = len(texts)\n",
    "print(f\"Количество строк: {N}\")\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "cell 2\n",
    "Каталоги для результатов\n",
    "\"\"\"\n",
    "EMB_DIR       = pathlib.Path(\"embeddings\") ; EMB_DIR.mkdir(exist_ok=True)\n",
    "DIST_DIR_ROOT = pathlib.Path(\"distances\")  ; DIST_DIR_ROOT.mkdir(exist_ok=True)\n",
    "HM_DIR        = pathlib.Path(\"heatmaps\")   ; HM_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "cell 3\n",
    "Список моделей. Добавляйте / убирайте по необходимости.\n",
    "Ключ словаря — читабельное имя, значение — id в HuggingFace Hub.\n",
    "\"\"\"\n",
    "MODELS = {\n",
    "    \"all-MiniLM-L6-v2\":   \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"all-mpnet-base-v2\":  \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"bge-base-en-v1.5\":   \"BAAI/bge-base-en-v1.5\",\n",
    "    \"bge-large-en-v1.5\":  \"BAAI/bge-large-en-v1.5\",\n",
    "    \"roberta-large\":     \"roberta-large\",\n",
    "    \"deberta-v3-large\":  \"microsoft/deberta-v3-large\",\n",
    "}\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH  = 32                         # подстройте под память\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "cell 4\n",
    "Функция для быстрой генерации эмбеддингов через SentenceTransformers\n",
    "normalize_embeddings=True сразу даёт l2-нормированные вектора — удобно для косинуса.\n",
    "\"\"\"\n",
    "def build_embeddings(model_id: str, texts, batch_size=BATCH):\n",
    "    encoder = SentenceTransformer(model_id, device=DEVICE)\n",
    "    emb = encoder.encode(\n",
    "        texts,\n",
    "        batch_size           = batch_size,\n",
    "        show_progress_bar    = True,\n",
    "        convert_to_numpy     = True,\n",
    "        normalize_embeddings = True\n",
    "    )\n",
    "    return emb.astype(np.float32)\n",
    "\n",
    "# %%\n",
    "\"\"\"\n",
    "cell 5\n",
    "Основной цикл по моделям\n",
    "\"\"\"\n",
    "for name, hub_id in MODELS.items():\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    # 1) эмбеддинги\n",
    "    emb_path = EMB_DIR / f\"{name}.npy\"\n",
    "    if emb_path.exists():\n",
    "        emb = np.load(emb_path)\n",
    "        print(\"✓ Embeddings загружены из кеша\")\n",
    "    else:\n",
    "        emb = build_embeddings(hub_id, texts)\n",
    "        np.save(emb_path, emb)\n",
    "        print(\"✓ Embeddings сохранены:\", emb.shape)\n",
    "    \n",
    "    # 2) матрица косинусных расстояний\n",
    "    dist_dir = DIST_DIR_ROOT / name ; dist_dir.mkdir(exist_ok=True)\n",
    "    dist_csv = dist_dir / \"cosine_distances.csv\"\n",
    "    if dist_csv.exists():\n",
    "        print(\"✓ Distance-matrix уже есть, пропускаю расчёт\")\n",
    "        dists = pd.read_csv(dist_csv, index_col=0).values\n",
    "    else:\n",
    "        print(\"… считаю матрицу расстояний (это O(N²) ≈ %.1f М)\" % (N**2/1e6))\n",
    "        dists = cosine_distances(emb)           # shape (N, N)\n",
    "        # сохраняем CSV — строки и столбцы пронумерованы id\n",
    "        pd.DataFrame(dists, index=df.id, columns=df.id)\\\n",
    "          .to_csv(dist_csv, index_label=\"id\")\n",
    "        print(\"✓ Distance-matrix сохранена:\", dist_csv)\n",
    "    \n",
    "    # 3) тепловая карта\n",
    "    hm_path = HM_DIR / f\"{name}.png\"\n",
    "    if not hm_path.exists():\n",
    "        print(\"… рисую heatmap\")\n",
    "        plt.figure(figsize=(8, 7))\n",
    "        sns.heatmap(dists, cmap=\"viridis\", cbar_kws=dict(label=\"cosine distance\"),\n",
    "                    xticklabels=False, yticklabels=False)\n",
    "        plt.title(f\"Cosine-distance heatmap — {name}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(hm_path, dpi=150)\n",
    "        plt.close()\n",
    "        print(\"✓ Heatmap сохранён:\", hm_path)\n",
    "    else:\n",
    "        print(\"✓ Heatmap уже есть\")\n",
    "\n",
    "print(\"\\nГотово ✅\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
